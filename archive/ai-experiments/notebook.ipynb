{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ENV Variables\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = \"http://localhost:1234/v1\"\n",
    "os.environ['OPENAI_API_KEY'] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Define a class that uses the HTTP API to get embeddings\n",
    "class HTTPEmbeddingModel(Embeddings):\n",
    "    def __init__(self, api_url: str, model_name: str):\n",
    "        \"\"\"\n",
    "        Initialize with the base URL of the HTTP server and model name.\n",
    "        \n",
    "        :param api_url: The API endpoint that returns the embeddings.\n",
    "        :param model_name: The model to use when making the request.\n",
    "        \"\"\"\n",
    "        self.api_url = api_url\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Get the embedding for a single piece of text by making an HTTP request.\n",
    "        \n",
    "        :param text: The text to get embeddings for.\n",
    "        :return: A list of floats representing the embedding.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"input\": text\n",
    "        }\n",
    "\n",
    "        response = requests.post(self.api_url, json=payload, headers={\"Content-Type\": \"application/json\"})\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Error getting embedding: {response.text}\")\n",
    "        \n",
    "        response_json = response.json()\n",
    "\n",
    "        # Extract the first embedding from the \"data\" field\n",
    "        embedding_data = response_json.get(\"data\", [])\n",
    "        if len(embedding_data) == 0:\n",
    "            raise ValueError(\"No embeddings found in the response.\")\n",
    "\n",
    "        # Assuming we are interested in the first embedding returned\n",
    "        return embedding_data[0].get(\"embedding\", [])\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Embed a list of documents (texts).\n",
    "        \n",
    "        :param texts: List of documents to embed.\n",
    "        :return: A list of lists, where each inner list is an embedding.\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            embedding = self.get_embedding(text)\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Embed a single query (text).\n",
    "        \n",
    "        :param text: The query text to embed.\n",
    "        :return: A list of floats representing the embedding.\n",
    "        \"\"\"\n",
    "        return self.get_embedding(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SQLiteVSS\n",
    "from typing import List\n",
    "\n",
    "# Instantiate the HTTP embedding model\n",
    "api_url = \"http://127.0.0.1:1234/v1/embeddings\"\n",
    "model_name = \"nomic-embed-text-v1.5\"\n",
    "embd = HTTPEmbeddingModel(api_url=api_url, model_name=model_name)\n",
    "texts = [\n",
    "    \"Prompt engineering is a methodology that focuses on the design and implementation of prompts to influence behavior.\",\n",
    "    \"Kshitij Shah is a software engineer who does no work.\",\n",
    "]\n",
    "\n",
    "# Add the documents to the vectorstore using the custom HTTP embedding model\n",
    "db = SQLiteVSS.from_texts(\n",
    "    texts=texts,      # Extract the text from the document chunks\n",
    "    embedding=embd,   # Use your custom embedding model here\n",
    "    table=\"state_union\",\n",
    "    db_file=\"/tmp/vss.db\",\n",
    ")\n",
    "\n",
    "# Perform a similarity search on the vectorstore\n",
    "query = \"Tell me about the coders in the company\"\n",
    "data = db.similarity_search(query)\n",
    "\n",
    "print(\"Embedding Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"datasource\": \"vectorstore\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Generate JSON schema\n",
    "route_query_schema = RouteQuery.model_json_schema()\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in Sydney is cloudy with some sunshine. The high temperature is 26°C and the low temperature tonight will be around 16°C. There will be mainly clear skies early, then areas of low clouds forming later.\\n\\nAs for traffic conditions in Sydney, there is currently a traffic jam in the middle western part of the city.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
