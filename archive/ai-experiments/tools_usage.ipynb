{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_definitions = \"\"\"[\n",
    "    {\n",
    "        \"name\": \"get_user_info\",\n",
    "        \"description\": \"Retrieve details for a specific user by their unique identifier. Note that the provided function is in Python 3 syntax.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"dict\",\n",
    "            \"required\": [\n",
    "                \"dank_man\"\n",
    "            ],\n",
    "            \"properties\": {\n",
    "                \"dank_man\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The unique identifier of the user. It is used to fetch the specific user details from the database.\"\n",
    "            },\n",
    "            \"special\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any special information or parameters that need to be considered while fetching user details.\",\n",
    "                \"default\": \"none\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def get_user_info(dank_man, special=\"none\"):\n",
    "    print(\"User ID: \", dank_man)\n",
    "    print(\"Special: \", special)\n",
    "    print(\"Rugved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert in composing functions. You are given a question and a set of possible functions. \n",
    "Based on the question, you will need to make one or more function/tool calls to achieve the purpose. \n",
    "If none of the function can be used, point it out. If the given question lacks the parameters required by the function,\n",
    "also point it out. You should only return the function call in tools call sections.\n",
    "\n",
    "If you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\\n\n",
    "You SHOULD NOT include any other text in the response.\n",
    "\n",
    "Here is a list of functions in JSON format that you can invoke.\\n\\n{functions}\\n\"\"\".format(functions=function_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you retrieve the details for the user with the ID 7890, who has black as their special request?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# Set ENV Variables\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = \"http://localhost:1234/v1\"\n",
    "os.environ['OPENAI_API_KEY'] = \"test\"\n",
    "\n",
    "LLAMA_3_2 = \"lmstudio-community/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q4_K_M.gguf\"\n",
    "LLAMA_3_1 = \"lmstudio-community/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct-Q4_K_M.gguf\"\n",
    "llm_3_2 = ChatOpenAI(model=LLAMA_3_2, temperature=0)\n",
    "llm_3_1 = ChatOpenAI(model=LLAMA_3_1, temperature=0)\n",
    "tools = [get_user_info]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" [get_user_info(dank_man=7890, special='black')]\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 344, 'total_tokens': 359, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama-3.2-1b-instruct', 'system_fingerprint': 'llama-3.2-1b-instruct', 'finish_reason': 'stop', 'logprobs': None} id='run-48fe1204-8a99-4a4e-bbbe-dbf4981a098a-0' usage_metadata={'input_tokens': 344, 'output_tokens': 15, 'total_tokens': 359}\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm_3_1.bind_tools(tools)\n",
    "res = llm_3_1.invoke(system_prompt + query)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [get_user_info(dank_man=7890, special='black')]\n",
      "User ID:  7890\n",
      "Special:  black\n",
      "Rugved!\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "# Now implement the tools function using the response from the model\n",
    "tools_call = res.content\n",
    "print(tools_call)\n",
    "tools_call = eval(tools_call)\n",
    "print(tools_call)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
